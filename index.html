<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>In-App Camera Zoom with Automatic Hand & Lighting Detection</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- TensorFlow.js CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <!-- MediaPipe Hands CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675469240/hands.js"></script>
    <!-- HandPose model from TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose@0.0.7/dist/handpose.min.js"></script>

    <style>
        /* Custom styles for better visual appeal */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f0f2f5;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            margin: 0;
        }
        .container {
            background-color: #ffffff;
            border-radius: 1.5rem; /* More rounded corners */
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
            overflow: hidden;
            max-width: 90vw; /* Responsive width */
            width: 500px; /* Max width for desktop */
        }
        .camera-area {
            position: relative; /* Needed for absolute positioning of overlay */
            width: 100%;
            padding-top: 75%; /* 4:3 aspect ratio (height / width * 100%) */
            overflow: hidden;
            border-radius: 1.5rem 1.5rem 0 0;
            background-color: #000; /* Black background for video area */
        }
        video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover; /* Ensures video fills the area without distortion */
            display: block;
            transform: scaleX(-1); /* Mirror the video horizontally for a "selfie" view */
        }
        /* Hidden canvas for processing video frames */
        #hiddenCanvas {
            display: none;
        }
        .hand-outline-overlay {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%); /* Center the overlay */
            width: 60%; /* Size of the outline relative to camera area */
            height: 60%;
            border: 4px solid; /* Border color will be set by JS */
            border-radius: 1rem; /* Rounded corners for the outline */
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 1.5rem;
            color: white;
            font-weight: bold;
            pointer-events: none; /* Allow clicks to pass through to video/buttons below */
            transition: border-color 0.3s ease-in-out; /* Smooth color transition */
        }
        .red-outline {
            border-color: #ef4444; /* Red color for no hand */
        }
        .green-outline {
            border-color: #22c55e; /* Green color for hand detected */
        }
        .controls {
            padding: 1.5rem;
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        .button-group {
            display: flex;
            justify-content: center;
            gap: 0.75rem;
            flex-wrap: wrap; /* Allow buttons to wrap on smaller screens */
        }
        button {
            padding: 0.75rem 1.5rem;
            border-radius: 0.75rem; /* Rounded buttons */
            font-weight: 600;
            transition: all 0.2s ease-in-out;
            cursor: pointer;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            border: none; /* Remove default border */
        }
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }
        button:active {
            transform: translateY(0);
            box-shadow: 0 2px 4px -1px rgba(0, 0, 0, 0.06), 0 1px 2px -1px rgba(0, 0, 0, 0.04);
        }
        .btn-primary {
            background-color: #4f46e5;
            color: white;
        }
        .btn-primary:hover {
            background-color: #4338ca;
        }
        .btn-secondary {
            background-color: #e5e7eb;
            color: #374151;
        }
        .btn-secondary:hover {
            background-color: #d1d5db;
        }
        input[type="range"] {
            width: 100%;
            -webkit-appearance: none; /* Remove default styling */
            height: 8px;
            background: #e0e7ff; /* Light blue track */
            border-radius: 5px;
            outline: none;
            transition: opacity .2s;
        }
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            background: #4f46e5; /* Primary color thumb */
            border-radius: 50%;
            cursor: pointer;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }
        input[type="range"]::-moz-range-thumb {
            width: 20px;
            height: 20px;
            background: #4f46e5;
            border-radius: 50%;
            cursor: pointer;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }
        #message-box {
            padding: 0.75rem;
            border-radius: 0.5rem;
            text-align: center;
            font-size: 0.875rem;
            display: none; /* Hidden by default */
            margin-bottom: 0.5rem;
        }
        .message-info {
            background-color: #e0e7ff; /* light blue */
            color: #4f46e5; /* blue */
        }
        .message-warning {
            background-color: #fffbeb; /* light yellow */
            color: #f59e0b; /* yellow */
        }
        .message-error {
            background-color: #fef2f2; /* light red */
            color: #ef4444; /* red */
        }
        .message-success {
            background-color: #ecfdf5; /* light green */
            color: #10b981; /* green */
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="camera-area">
            <video id="cameraFeed" autoplay playsinline></video>
            <!-- Hidden canvas for processing video frames -->
            <canvas id="hiddenCanvas"></canvas>
            <!-- Hand Outline Overlay -->
            <div id="handOutlineOverlay" class="hand-outline-overlay red-outline">
                <!-- You could add an SVG icon here for a more detailed hand outline -->
            </div>
        </div>
        <div class="controls">
            <div id="message-box" class="message-info"></div>
            <div class="button-group">
                <button id="zoomOutBtn" class="btn-secondary">Zoom Out</button>
                <button id="zoomInBtn" class="btn-primary">Zoom In</button>
            </div>
            <label for="zoomSlider" class="text-center text-gray-700 font-medium">Zoom Level:</label>
            <input type="range" id="zoomSlider" min="0" max="100" value="0" class="w-full">
        </div>
    </div>

    <script>
        // Get references to DOM elements
        const cameraFeed = document.getElementById('cameraFeed');
        const zoomInBtn = document.getElementById('zoomInBtn');
        const zoomOutBtn = document.getElementById('zoomOutBtn');
        const zoomSlider = document.getElementById('zoomSlider');
        const messageBox = document.getElementById('message-box');
        const handOutlineOverlay = document.getElementById('handOutlineOverlay');
        const hiddenCanvas = document.getElementById('hiddenCanvas');
        const ctx = hiddenCanvas.getContext('2d');

        let mediaStream = null;
        let videoTrack = null;
        let zoomCapabilities = null;
        let currentZoom = 0; // Initialize current zoom level
        let isHandDetected = false; // State for actual hand detection
        let lightingCondition = 'unknown'; // State for lighting condition ('good', 'low', 'high')
        let handposeModel = null; // Variable to hold the loaded handpose model

        // Lighting thresholds (adjust as needed for your environment)
        const LOW_BRIGHTNESS_THRESHOLD = 60; // Average pixel value below this is considered low light
        const HIGH_BRIGHTNESS_THRESHOLD = 180; // Average pixel value above this is considered high light (overexposed)

        /**
         * Displays a message in the message box.
         * @param {string} message - The message to display.
         * @param {string} type - The type of message ('info', 'warning', 'error', 'success').
         */
        function updateMessageBox(message, type = 'info') {
            messageBox.textContent = message;
            messageBox.style.display = 'block';
            messageBox.className = `message-box message-${type}`; // Apply dynamic class
        }

        /**
         * Initializes the camera feed and sets up zoom controls.
         */
        async function initCamera() {
            try {
                // Request access to the user's camera
                mediaStream = await navigator.mediaDevices.getUserMedia({ video: true });
                cameraFeed.srcObject = mediaStream;

                // Get the video track from the stream
                videoTrack = mediaStream.getVideoTracks()[0];

                // Check if zoom capabilities are supported by the video track
                const capabilities = videoTrack.getCapabilities();
                if (capabilities.zoom) {
                    zoomCapabilities = capabilities.zoom;
                    zoomSlider.min = zoomCapabilities.min;
                    zoomSlider.max = zoomCapabilities.max;
                    zoomSlider.step = zoomCapabilities.step;
                    currentZoom = zoomCapabilities.min; // Start at min zoom
                    zoomSlider.value = currentZoom;
                    updateZoomDisplay(); // Update initial display
                    updateMessageBox('Camera access granted. Zoom controls available.', 'info');
                } else {
                    updateMessageBox('Zoom is not supported by your camera or browser.', 'warning');
                    zoomInBtn.disabled = true;
                    zoomOutBtn.disabled = true;
                    zoomSlider.disabled = true;
                }
                updateHandOutline(); // Set initial outline color to red

                // Wait for the video to load metadata to get its dimensions
                cameraFeed.onloadedmetadata = () => {
                    hiddenCanvas.width = cameraFeed.videoWidth;
                    hiddenCanvas.height = cameraFeed.videoHeight;
                    // Start hand detection loop after camera is ready
                    startDetectionLoop();
                };

            } catch (error) {
                console.error('Error accessing camera:', error);
                if (error.name === 'NotAllowedError') {
                    updateMessageBox('Camera access denied. Please allow camera access in your browser settings.', 'error');
                } else if (error.name === 'NotFoundError') {
                    updateMessageBox('No camera found on your device.', 'error');
                } else {
                    updateMessageBox(`Error: ${error.message}. Could not access camera.`, 'error');
                }
                zoomInBtn.disabled = true;
                zoomOutBtn.disabled = true;
                zoomSlider.disabled = true;
            }
        }

        /**
         * Applies the new zoom level to the video track.
         * @param {number} newZoom - The desired zoom level.
         */
        function applyZoom(newZoom) {
            if (!videoTrack || !zoomCapabilities) {
                updateMessageBox('Camera not ready or zoom not supported.', 'warning');
                return;
            }

            // Clamp the new zoom value within the capabilities' min and max
            newZoom = Math.max(zoomCapabilities.min, Math.min(newZoom, zoomCapabilities.max));

            // Apply the new constraints
            videoTrack.applyConstraints({
                advanced: [{ zoom: newZoom }]
            }).then(() => {
                currentZoom = newZoom;
                zoomSlider.value = currentZoom;
                updateZoomDisplay();
            }).catch(error => {
                console.error('Error applying zoom:', error);
                updateMessageBox(`Failed to apply zoom: ${error.message}`, 'error');
            });
        }

        /**
         * Updates the zoom slider and potentially a text display (if added).
         */
        function updateZoomDisplay() {
            // This function is currently a placeholder.
            // You could add a text element here to show the current zoom value if desired.
        }

        /**
         * Updates the hand outline color based on the isHandDetected state.
         */
        function updateHandOutline() {
            if (isHandDetected) {
                handOutlineOverlay.classList.remove('red-outline');
                handOutlineOverlay.classList.add('green-outline');
            } else {
                handOutlineOverlay.classList.remove('green-outline');
                handOutlineOverlay.classList.add('red-outline');
            }
        }

        /**
         * Analyzes the lighting condition from the provided ImageData.
         * @param {ImageData} imageData - The image data from the canvas.
         * @returns {string} 'good', 'low', or 'high'.
         */
        function analyzeLighting(imageData) {
            const data = imageData.data;
            let totalBrightness = 0;
            const pixelCount = data.length / 4; // Each pixel has R, G, B, A

            if (pixelCount === 0) return 'unknown';

            // Calculate average brightness (luminance)
            for (let i = 0; i < data.length; i += 4) {
                // Approximate luminance: 0.299*R + 0.587*G + 0.114*B
                totalBrightness += (data[i] * 0.299 + data[i + 1] * 0.587 + data[i + 2] * 0.114);
            }
            const averageBrightness = totalBrightness / pixelCount;

            if (averageBrightness < LOW_BRIGHTNESS_THRESHOLD) {
                return 'low';
            } else if (averageBrightness > HIGH_BRIGHTNESS_THRESHOLD) {
                return 'high';
            } else {
                return 'good';
            }
        }

        /**
         * Updates the combined status message in the message box.
         */
        function updateCombinedStatusMessage() {
            let handStatus = isHandDetected ? 'Hand detected!' : 'No hand visible.';
            let lightingStatusText = '';
            let messageType = 'info';

            switch (lightingCondition) {
                case 'low':
                    lightingStatusText = 'Lighting is too low. Move to a brighter area.';
                    messageType = 'warning';
                    break;
                case 'high':
                    lightingStatusText = 'Lighting is too bright. Avoid glare.';
                    messageType = 'warning';
                    break;
                case 'good':
                    lightingStatusText = 'Lighting looks good for details.';
                    messageType = 'success';
                    break;
                default:
                    lightingStatusText = 'Analyzing lighting...';
                    messageType = 'info';
            }

            const fullMessage = `${handStatus} ${lightingStatusText}`;
            updateMessageBox(fullMessage, messageType);
        }


        /**
         * Loads the Handpose model.
         */
        async function loadHandposeModel() {
            updateMessageBox('Loading hand detection model...', 'info');
            try {
                handposeModel = await handpose.load();
                updateMessageBox('Hand detection model loaded successfully!', 'info');
            } catch (error) {
                console.error('Error loading handpose model:', error);
                updateMessageBox('Failed to load hand detection model. Hand detection will not work.', 'error');
            }
        }

        /**
         * Starts the continuous hand and lighting detection loop.
         */
        async function startDetectionLoop() {
            if (!handposeModel || !cameraFeed.videoWidth || !cameraFeed.videoHeight) {
                // If model isn't loaded or video dimensions aren't ready, try again after a short delay
                requestAnimationFrame(startDetectionLoop);
                return;
            }

            // Draw the video frame onto the hidden canvas
            ctx.drawImage(cameraFeed, 0, 0, hiddenCanvas.width, hiddenCanvas.height);

            // Get image data for lighting analysis
            const imageData = ctx.getImageData(0, 0, hiddenCanvas.width, hiddenCanvas.height);
            lightingCondition = analyzeLighting(imageData);

            // Perform hand detection
            const predictions = await handposeModel.estimateHands(hiddenCanvas);

            // Determine if a hand is detected
            isHandDetected = predictions.length > 0;

            // Update UI based on detection and lighting
            updateHandOutline();
            updateCombinedStatusMessage();

            // Request the next animation frame to continue the loop
            requestAnimationFrame(startDetectionLoop);
        }

        // Event Listeners
        zoomInBtn.addEventListener('click', () => {
            if (zoomCapabilities) {
                // Increase zoom by a step, or a fixed amount if step is not granular enough
                let newZoom = currentZoom + (zoomCapabilities.step || (zoomCapabilities.max - zoomCapabilities.min) / 10);
                applyZoom(newZoom);
            }
        });

        zoomOutBtn.addEventListener('click', () => {
            if (zoomCapabilities) {
                // Decrease zoom by a step
                let newZoom = currentZoom - (zoomCapabilities.step || (zoomCapabilities.max - zoomCapabilities.min) / 10);
                applyZoom(newZoom);
            }
        });

        zoomSlider.addEventListener('input', (event) => {
            if (zoomCapabilities) {
                const newZoom = parseFloat(event.target.value);
                applyZoom(newZoom);
            }
        });

        // Initialize camera and load handpose model when the window loads
        window.onload = async () => {
            await loadHandposeModel(); // Load the ML model first
            await initCamera(); // Then initialize the camera
        };

        // Cleanup: Stop camera stream when the page is closed or navigated away
        window.addEventListener('beforeunload', () => {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>
